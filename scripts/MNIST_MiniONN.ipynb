{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyFvxvSgsTqQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-uJEFsv4tBBY"
   },
   "source": [
    "## Lets get the data, model and setup trainnig code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KaC8fIULs7XK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images 60000, Test images 10000\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(datasets.MNIST(\"./\", train=True, transform=transforms.ToTensor(), download=True), batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(datasets.MNIST(\"./\", train=False, transform=transforms.ToTensor(), download=True), batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Training images {len(train_loader.dataset)}, Test images {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRKHX6Ssp2Hz"
   },
   "outputs": [],
   "source": [
    "class mnist_model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(mnist_model, self).__init__()\n",
    "    self.layer1 = nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=0)\n",
    "    self.layer2 = nn.Conv2d(16, 16, kernel_size=5, stride=1, padding=0)\n",
    "    self.layer3 = nn.Linear(256, 100, bias=True)\n",
    "    self.layer4 = nn.Linear(100, 10, bias=True)\n",
    "\n",
    "    self.act = nn.ReLU()\n",
    "    self.pool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.act(self.layer1(x))\n",
    "    out = self.pool(out)\n",
    "    out = self.act(self.layer2(out))\n",
    "    out = self.pool(out)\n",
    "    out = out.view(-1, 256)\n",
    "    out = self.act(self.layer3(out))\n",
    "    out = self.act(self.layer4(out))\n",
    "    return out\n",
    "\n",
    "  def output(self, x):\n",
    "    out1 = self.act(self.layer1(x))\n",
    "    out1 = self.pool(out1)\n",
    "    out2 = self.act(self.layer2(out1))\n",
    "    out2 = self.pool(out2)\n",
    "    out2 = out2.view(-1, 256)\n",
    "    out3 = self.act(self.layer3(out2))\n",
    "    out4 = self.act(self.layer4(out3))    \n",
    "    return out1, out2, out3, out4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Suh22BC9tMTj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_model(\n",
      "  (layer1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (layer2): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (layer3): Linear(in_features=256, out_features=100, bias=True)\n",
      "  (layer4): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (act): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = mnist_model().cuda()\n",
    "print(model)\n",
    "\n",
    "epochs = 15\n",
    "lr = 0.1\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lrs = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ztvyum2f-XqU"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pOYNVw8B-aKz"
   },
   "outputs": [],
   "source": [
    "def get_acc(model, loader):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for img, label in loader:\n",
    "    correct += torch.sum(torch.argmax(model(img.cuda()), -1).cpu() == label).item()\n",
    "    total += len(img)\n",
    "  return 100*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yk0nHkbhtPkz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.1\n",
      "Epoch 0, training accuracy 68.44833333333334, test accuracy 68.33\n",
      "lr 0.09890738003669029\n",
      "Epoch 1, training accuracy 78.96, test accuracy 78.89\n",
      "lr 0.09567727288213004\n",
      "Epoch 2, training accuracy 87.80333333333333, test accuracy 87.72\n",
      "lr 0.09045084971874738\n",
      "Epoch 3, training accuracy 88.81666666666666, test accuracy 88.74\n",
      "lr 0.08345653031794292\n",
      "Epoch 4, training accuracy 88.92333333333333, test accuracy 88.73\n",
      "lr 0.07500000000000001\n",
      "Epoch 5, training accuracy 89.30333333333333, test accuracy 89.03\n",
      "lr 0.06545084971874739\n",
      "Epoch 6, training accuracy 89.44666666666667, test accuracy 89.13\n",
      "lr 0.05522642316338269\n",
      "Epoch 7, training accuracy 89.51333333333334, test accuracy 89.13\n",
      "lr 0.04477357683661735\n",
      "Epoch 8, training accuracy 89.46833333333333, test accuracy 89.18\n",
      "lr 0.03454915028125265\n",
      "Epoch 9, training accuracy 89.68, test accuracy 89.13\n",
      "lr 0.02500000000000002\n",
      "Epoch 10, training accuracy 89.69, test accuracy 89.18\n",
      "lr 0.01654346968205711\n",
      "Epoch 11, training accuracy 89.72666666666667, test accuracy 89.19\n",
      "lr 0.009549150281252635\n",
      "Epoch 12, training accuracy 89.77333333333333, test accuracy 89.2\n",
      "lr 0.004322727117869953\n",
      "Epoch 13, training accuracy 89.78, test accuracy 89.21\n",
      "lr 0.001092619963309716\n",
      "Epoch 14, training accuracy 89.78, test accuracy 89.19\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "  print(\"lr\", optimizer.param_groups[0][\"lr\"])\n",
    "  for img, label in train_loader:\n",
    "    out = model(img.cuda())\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(out, label.cuda())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  lrs.step()\n",
    "  print(f\"Epoch {e}, training accuracy {get_acc(model, train_loader)}, test accuracy {get_acc(model, test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QsQBF-eWFDY7"
   },
   "source": [
    "## Extract weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CdQe9RA0vthi"
   },
   "outputs": [],
   "source": [
    "params = [(name, p.data.cpu().numpy()) for (name, p) in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DO_6VdePwxF_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer layer1, type weight, shape (16, 1, 5, 5)\n",
      "Layer layer1, type bias, shape (16,)\n",
      "Layer layer2, type weight, shape (16, 16, 5, 5)\n",
      "Layer layer2, type bias, shape (16,)\n",
      "Layer layer3, type weight, shape (100, 256)\n",
      "Layer layer3, type bias, shape (100,)\n",
      "Layer layer4, type weight, shape (10, 100)\n",
      "Layer layer4, type bias, shape (10,)\n"
     ]
    }
   ],
   "source": [
    "for (name, p) in params:\n",
    "  print(f\"Layer {name.split('.')[0]}, type {name.split('.')[1]}, shape {p.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lypaj9GkFrUU"
   },
   "outputs": [],
   "source": [
    "#print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcatFuNhe1fY"
   },
   "source": [
    "## Visualize hidden activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r6lxIEFReMxL"
   },
   "outputs": [],
   "source": [
    "# print(model.children())\n",
    "# out = list(model.children())[0](img.cuda()).data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4rd-AKLbeL-A"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# for _ in range(out.shape[1]):\n",
    "#   plt.figure(figsize=(1, 1))\n",
    "#   plt.imshow(out[0, 0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVz78PBcFzka"
   },
   "outputs": [],
   "source": [
    "for img, label in train_loader:\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACfBKOB3v7Dm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.28125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"./MiniONN/\"\n",
    "import os\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "np.savetxt(fname=path+\"label\", delimiter=\" \", X=label.tolist())\n",
    "print(get_acc(model, ([img,label],)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eiqkXaaBZUci"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "np.savetxt(fname=path+\"input_0\", delimiter=\" \", X=img.cuda().view(-1, 784).tolist())\n",
    "np.savetxt(fname=path+\"outputlayer1_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[0].data.cpu().view(-1))\n",
    "np.savetxt(fname=path+\"outputlayer2_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[1].tolist())\n",
    "np.savetxt(fname=path+\"outputlayer3_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[2].tolist())\n",
    "np.savetxt(fname=path+\"outputlayer4_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[3].tolist())\n",
    "\n",
    "np.savetxt(fname=path+\"weight1_0\", delimiter=\" \", X=params[0][1].reshape(5*5*1, 16).tolist())\n",
    "np.savetxt(fname=path+\"bias1_0\", delimiter=\" \", X=params[1][1].tolist())\n",
    "np.savetxt(fname=path+\"weight2_0\", delimiter=\" \", X=params[2][1].reshape(5*5*16, 16).tolist())\n",
    "np.savetxt(fname=path+\"bias2_0\", delimiter=\" \", X=params[3][1].tolist())\n",
    "np.savetxt(fname=path+\"weight3_0\", delimiter=\" \", X=params[4][1].tolist())\n",
    "np.savetxt(fname=path+\"bias3_0\", delimiter=\" \", X=params[5][1].tolist())\n",
    "np.savetxt(fname=path+\"weight4_0\", delimiter=\" \", X=params[6][1].tolist())\n",
    "np.savetxt(fname=path+\"bias4_0\", delimiter=\" \", X=params[7][1].tolist())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_MiniONN.ipynb",
   "provenance": [
    {
     "file_id": "1G0aq7Vn-bomx5TTWCkUXm2iAPtQjYxxl",
     "timestamp": 1597179603592
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
