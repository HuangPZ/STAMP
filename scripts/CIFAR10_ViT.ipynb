{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyFvxvSgsTqQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-uJEFsv4tBBY"
   },
   "source": [
    "## Lets get the data, model and setup trainnig code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KaC8fIULs7XK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training images 50000, Test images 10000\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(datasets.CIFAR10(\"./\", train=True, transform=transforms.ToTensor(), download=True), batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(datasets.CIFAR10(\"./\", train=False, transform=transforms.ToTensor(), download=True), batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Training images {len(train_loader.dataset)}, Test images {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRKHX6Ssp2Hz"
   },
   "outputs": [],
   "source": [
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# helpers\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "# classes\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
    "            ]))\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n",
    "        super().__init__()\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "\n",
    "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
    "        patch_dim = channels * patch_height * patch_width\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        return self.mlp_head(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Suh22BC9tMTj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT(\n",
      "  (to_patch_embedding): Sequential(\n",
      "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=32, p2=32)\n",
      "    (1): Linear(in_features=3072, out_features=1024, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (transformer): Transformer(\n",
      "    (layers): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=1536, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "              (1): GELU()\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "              (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=1536, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "              (1): GELU()\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "              (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=1536, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "              (1): GELU()\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "              (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=1536, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "              (1): GELU()\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "              (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=1536, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "              (1): GELU()\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "              (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=1536, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "              (1): GELU()\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "              (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (to_latent): Identity()\n",
      "  (mlp_head): Sequential(\n",
      "    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=1024, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ViT(image_size = 256,\n",
    "    patch_size = 32,\n",
    "    num_classes = 1000,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    mlp_dim = 2048\n",
    ").cuda()\n",
    "print(model)\n",
    "\n",
    "epochs = 15\n",
    "lr = 0.1\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lrs = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ztvyum2f-XqU"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pOYNVw8B-aKz"
   },
   "outputs": [],
   "source": [
    "def get_acc(model, loader):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for img, label in loader:\n",
    "    correct += torch.sum(torch.argmax(model(img.cuda()), -1).cpu() == label).item()\n",
    "    total += len(img)\n",
    "  return 100*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yk0nHkbhtPkz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.1\n",
      "Epoch 0, training accuracy 97.05666666666667, test accuracy 97.15\n",
      "lr 0.09890738003669029\n",
      "Epoch 1, training accuracy 98.35333333333334, test accuracy 98.37\n",
      "lr 0.09567727288213004\n",
      "Epoch 2, training accuracy 98.69, test accuracy 98.59\n",
      "lr 0.09045084971874738\n",
      "Epoch 3, training accuracy 98.995, test accuracy 98.95\n",
      "lr 0.08345653031794292\n",
      "Epoch 4, training accuracy 99.21833333333333, test accuracy 98.98\n",
      "lr 0.07500000000000001\n",
      "Epoch 5, training accuracy 99.33666666666667, test accuracy 99.02\n",
      "lr 0.06545084971874739\n",
      "Epoch 6, training accuracy 99.345, test accuracy 98.98\n",
      "lr 0.05522642316338269\n",
      "Epoch 7, training accuracy 99.53666666666666, test accuracy 99.04\n",
      "lr 0.04477357683661735\n",
      "Epoch 8, training accuracy 99.66833333333334, test accuracy 99.16\n",
      "lr 0.03454915028125265\n",
      "Epoch 9, training accuracy 99.695, test accuracy 99.18\n",
      "lr 0.02500000000000002\n",
      "Epoch 10, training accuracy 99.73833333333333, test accuracy 99.16\n",
      "lr 0.01654346968205711\n",
      "Epoch 11, training accuracy 99.76, test accuracy 99.15\n",
      "lr 0.009549150281252635\n",
      "Epoch 12, training accuracy 99.77, test accuracy 99.17\n",
      "lr 0.004322727117869953\n",
      "Epoch 13, training accuracy 99.77833333333334, test accuracy 99.17\n",
      "lr 0.001092619963309716\n",
      "Epoch 14, training accuracy 99.79166666666667, test accuracy 99.17\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "  print(\"lr\", optimizer.param_groups[0][\"lr\"])\n",
    "  for img, label in train_loader:\n",
    "    # print(img.shape, label.shape)\n",
    "    out = model(img.cuda())\n",
    "    # print(out.shape)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(out, label.cuda())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  lrs.step()\n",
    "  print(f\"Epoch {e}, training accuracy {get_acc(model, train_loader)}, test accuracy {get_acc(model, test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QsQBF-eWFDY7"
   },
   "source": [
    "## Extract weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CdQe9RA0vthi"
   },
   "outputs": [],
   "source": [
    "params = [(name, p.data.cpu().numpy()) for (name, p) in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DO_6VdePwxF_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer layer1, type weight, shape (20, 1, 5, 5)\n",
      "Layer layer1, type bias, shape (20,)\n",
      "Layer layer2, type weight, shape (50, 20, 5, 5)\n",
      "Layer layer2, type bias, shape (50,)\n",
      "Layer layer3, type weight, shape (500, 800)\n",
      "Layer layer3, type bias, shape (500,)\n",
      "Layer layer4, type weight, shape (10, 500)\n",
      "Layer layer4, type bias, shape (10,)\n"
     ]
    }
   ],
   "source": [
    "for (name, p) in params:\n",
    "  print(f\"Layer {name.split('.')[0]}, type {name.split('.')[1]}, shape {p.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lypaj9GkFrUU"
   },
   "outputs": [],
   "source": [
    "#print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcatFuNhe1fY"
   },
   "source": [
    "## Visualize hidden activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r6lxIEFReMxL"
   },
   "outputs": [],
   "source": [
    "# print(model.children())\n",
    "# out = list(model.children())[0](img.cuda()).data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4rd-AKLbeL-A"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# for _ in range(out.shape[1]):\n",
    "#   plt.figure(figsize=(1, 1))\n",
    "#   plt.imshow(out[0, 0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVz78PBcFzka"
   },
   "outputs": [],
   "source": [
    "for img, label in train_loader:\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 7, 1, 1, 7, 9, 1, 7, 7, 4, 7, 7, 7, 7, 2, 0, 3, 4, 4, 4, 1, 4, 2, 6,\n",
      "        2, 3, 3, 7, 5, 7, 5, 0, 8, 3, 3, 5, 4, 7, 3, 4, 5, 9, 8, 1, 9, 1, 7, 9,\n",
      "        3, 6, 3, 6, 7, 4, 2, 1, 5, 1, 1, 8, 9, 7, 5, 5, 4, 5, 6, 3, 9, 1, 8, 2,\n",
      "        3, 8, 5, 9, 1, 8, 3, 8, 7, 8, 6, 1, 3, 4, 6, 6, 0, 2, 3, 3, 9, 7, 5, 9,\n",
      "        1, 4, 6, 6, 0, 4, 4, 8, 6, 6, 8, 6, 2, 6, 3, 5, 6, 5, 7, 0, 5, 0, 5, 2,\n",
      "        0, 9, 2, 2, 1, 5, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACfBKOB3v7Dm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"./LeNet/\"\n",
    "import os\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "np.savetxt(fname=path+\"label\", delimiter=\" \", X=label.tolist())\n",
    "print(get_acc(model, ([img,label],)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eiqkXaaBZUci"
   },
   "outputs": [],
   "source": [
    "\n",
    "np.savetxt(fname=path+\"input_0\", delimiter=\" \", X=img.cuda().view(-1, 784).tolist())\n",
    "np.savetxt(fname=path+\"outputlayer1_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[0].data.cpu().view(-1))\n",
    "np.savetxt(fname=path+\"outputlayer2_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[1].tolist())\n",
    "np.savetxt(fname=path+\"outputlayer3_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[2].tolist())\n",
    "np.savetxt(fname=path+\"outputlayer4_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[3].tolist())\n",
    "\n",
    "np.savetxt(fname=path+\"weight1_0\", delimiter=\" \", X=params[0][1].reshape(5*5*1, 20).tolist())\n",
    "np.savetxt(fname=path+\"bias1_0\", delimiter=\" \", X=params[1][1].tolist())\n",
    "np.savetxt(fname=path+\"weight2_0\", delimiter=\" \", X=params[2][1].reshape(5*5*20, 50).tolist())\n",
    "np.savetxt(fname=path+\"bias2_0\", delimiter=\" \", X=params[3][1].tolist())\n",
    "np.savetxt(fname=path+\"weight3_0\", delimiter=\" \", X=params[4][1].tolist())\n",
    "np.savetxt(fname=path+\"bias3_0\", delimiter=\" \", X=params[5][1].tolist())\n",
    "np.savetxt(fname=path+\"weight4_0\", delimiter=\" \", X=params[6][1].tolist())\n",
    "np.savetxt(fname=path+\"bias4_0\", delimiter=\" \", X=params[7][1].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_LeNet.ipynb",
   "provenance": [
    {
     "file_id": "1G0aq7Vn-bomx5TTWCkUXm2iAPtQjYxxl",
     "timestamp": 1597179603592
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
