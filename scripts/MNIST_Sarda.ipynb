{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyFvxvSgsTqQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-uJEFsv4tBBY"
   },
   "source": [
    "## Lets get the data, model and setup training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KaC8fIULs7XK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7d79bd56d84adaa5b6ea2e5f79fd3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f508b1a51742d48da6302869b8019f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0830685a396646339a45443839aa9c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8afbdd850b5498d98b8b409de629821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "Processing...\n",
      "Done!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training images 60000, Test images 10000\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(datasets.MNIST(\"./\", train=True, transform=transforms.ToTensor(), download=True), batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(datasets.MNIST(\"./\", train=False, transform=transforms.ToTensor(), download=True), batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Training images {len(train_loader.dataset)}, Test images {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRKHX6Ssp2Hz"
   },
   "outputs": [],
   "source": [
    "class mnist_model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(mnist_model, self).__init__()\n",
    "    self.layer1 = nn.Conv2d(1, 5, kernel_size=2, stride=2, padding=0)\n",
    "    self.layer2 = nn.Linear(980, 100, bias=True)\n",
    "    self.layer3 = nn.Linear(100, 10, bias=True)\n",
    "    self.act = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.act(self.layer1(x))\n",
    "    out = out.view(-1, 980)\n",
    "    out = self.act(self.layer2(out))\n",
    "    out = self.layer3(out)\n",
    "    return out\n",
    "\n",
    "  def output(self, x):\n",
    "    out1 = self.act(self.layer1(x))\n",
    "    out1 = out1.view(-1, 980)\n",
    "    out2 = self.act(self.layer2(out1))\n",
    "    out3 = self.layer3(out2)\n",
    "    return out1, out2, out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Suh22BC9tMTj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_model(\n",
      "  (layer1): Conv2d(1, 5, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (layer2): Linear(in_features=980, out_features=100, bias=True)\n",
      "  (layer3): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (act): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = mnist_model().cuda()\n",
    "print(model)\n",
    "\n",
    "epochs = 15\n",
    "lr = 0.1\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lrs = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ztvyum2f-XqU"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pOYNVw8B-aKz"
   },
   "outputs": [],
   "source": [
    "def get_acc(model, loader):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for img, label in loader:\n",
    "    correct += torch.sum(torch.argmax(model(img.cuda()), -1).cpu() == label).item()\n",
    "    total += len(img)\n",
    "  return 100*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yk0nHkbhtPkz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.1\n",
      "Epoch 0, training accuracy 92.69, test accuracy 93.04\n",
      "lr 0.09890738003669029\n",
      "Epoch 1, training accuracy 95.78666666666666, test accuracy 95.81\n",
      "lr 0.09567727288213004\n",
      "Epoch 2, training accuracy 96.615, test accuracy 96.29\n",
      "lr 0.09045084971874738\n",
      "Epoch 3, training accuracy 97.34333333333333, test accuracy 96.89\n",
      "lr 0.08345653031794292\n",
      "Epoch 4, training accuracy 97.72, test accuracy 97.12\n",
      "lr 0.07500000000000001\n",
      "Epoch 5, training accuracy 97.71333333333334, test accuracy 97.11\n",
      "lr 0.06545084971874739\n",
      "Epoch 6, training accuracy 98.35833333333333, test accuracy 97.51\n",
      "lr 0.05522642316338269\n",
      "Epoch 7, training accuracy 98.52666666666667, test accuracy 97.58\n",
      "lr 0.04477357683661735\n",
      "Epoch 8, training accuracy 98.665, test accuracy 97.74\n",
      "lr 0.03454915028125265\n",
      "Epoch 9, training accuracy 98.82, test accuracy 97.9\n",
      "lr 0.02500000000000002\n",
      "Epoch 10, training accuracy 98.82666666666667, test accuracy 97.89\n",
      "lr 0.01654346968205711\n",
      "Epoch 11, training accuracy 98.90666666666667, test accuracy 97.83\n",
      "lr 0.009549150281252635\n",
      "Epoch 12, training accuracy 98.965, test accuracy 97.86\n",
      "lr 0.004322727117869953\n",
      "Epoch 13, training accuracy 98.97166666666666, test accuracy 97.84\n",
      "lr 0.001092619963309716\n",
      "Epoch 14, training accuracy 98.99666666666667, test accuracy 97.86\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "  print(\"lr\", optimizer.param_groups[0][\"lr\"])\n",
    "  for img, label in train_loader:\n",
    "    # print(img.shape, label.shape)\n",
    "    out = model(img.cuda())\n",
    "    # print(out.shape)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(out, label.cuda())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  lrs.step()\n",
    "  print(f\"Epoch {e}, training accuracy {get_acc(model, train_loader)}, test accuracy {get_acc(model, test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QsQBF-eWFDY7"
   },
   "source": [
    "## Extract weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CdQe9RA0vthi"
   },
   "outputs": [],
   "source": [
    "params = [(name, p.data.cpu().numpy()) for (name, p) in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DO_6VdePwxF_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer layer1, type weight, shape (5, 1, 2, 2)\n",
      "Layer layer1, type bias, shape (5,)\n",
      "Layer layer2, type weight, shape (100, 980)\n",
      "Layer layer2, type bias, shape (100,)\n",
      "Layer layer3, type weight, shape (10, 100)\n",
      "Layer layer3, type bias, shape (10,)\n"
     ]
    }
   ],
   "source": [
    "for (name, p) in params:\n",
    "  print(f\"Layer {name.split('.')[0]}, type {name.split('.')[1]}, shape {p.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lypaj9GkFrUU"
   },
   "outputs": [],
   "source": [
    "#print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcatFuNhe1fY"
   },
   "source": [
    "## Visualize hidden activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r6lxIEFReMxL"
   },
   "outputs": [],
   "source": [
    "# print(model.children())\n",
    "# out = list(model.children())[0](img.cuda()).data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4rd-AKLbeL-A"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# for _ in range(out.shape[1]):\n",
    "#   plt.figure(figsize=(1, 1))\n",
    "#   plt.imshow(out[0, 0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVz78PBcFzka"
   },
   "outputs": [],
   "source": [
    "for img, label in train_loader:\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACfBKOB3v7Dm",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.875\n",
      "[-2.5631444454193115, 0.36498868465423584, 5.231445789337158, 11.76509952545166, -10.27979850769043, 5.50112771987915, -8.185359954833984, -4.739908695220947, 1.422985315322876, 0.6781705021858215]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"./Sarda/\"\n",
    "import os\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "np.savetxt(fname=path+\"label\", delimiter=\" \", X=label.tolist())\n",
    "print(get_acc(model, ([img,label],)))\n",
    "print(model.output(img.cuda().view(128, 1, 28, 28))[2].tolist()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eiqkXaaBZUci"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "np.savetxt(fname=path+\"input_0\", delimiter=\" \", X=img.cuda().view(-1, 784).tolist())\n",
    "np.savetxt(fname=path+\"outputlayer1_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[0].tolist())\n",
    "np.savetxt(fname=path+\"outputlayer2_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[1].tolist())\n",
    "np.savetxt(fname=path+\"outputlayer3_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[2].tolist())\n",
    "\n",
    "np.savetxt(fname=path+\"weight1_0\", delimiter=\" \", X=params[0][1].reshape(2*2*1, 5).tolist())\n",
    "np.savetxt(fname=path+\"bias1_0\", delimiter=\" \", X=params[1][1].tolist())\n",
    "np.savetxt(fname=path+\"weight2_0\", delimiter=\" \", X=params[2][1].tolist())\n",
    "np.savetxt(fname=path+\"bias2_0\", delimiter=\" \", X=params[3][1].tolist())\n",
    "np.savetxt(fname=path+\"weight3_0\", delimiter=\" \", X=params[4][1].tolist())\n",
    "np.savetxt(fname=path+\"bias3_0\", delimiter=\" \", X=params[5][1].tolist())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_Sarda.ipynb",
   "provenance": [
    {
     "file_id": "1G0aq7Vn-bomx5TTWCkUXm2iAPtQjYxxl",
     "timestamp": 1597179603592
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
