{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyFvxvSgsTqQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-uJEFsv4tBBY"
   },
   "source": [
    "## Lets get the data, model and setup training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KaC8fIULs7XK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images 60000, Test images 10000\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(datasets.MNIST(\"./\", train=True, transform=transforms.ToTensor(), download=True), batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(datasets.MNIST(\"./\", train=False, transform=transforms.ToTensor(), download=True), batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Training images {len(train_loader.dataset)}, Test images {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRKHX6Ssp2Hz"
   },
   "outputs": [],
   "source": [
    "class mnist_model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(mnist_model, self).__init__()\n",
    "    self.layer1 = nn.Linear(784, 128, bias=True)\n",
    "    self.layer2 = nn.Linear(128, 128, bias=True)\n",
    "    self.layer3 = nn.Linear(128, 10, bias=True)\n",
    "    # self.act = nn.Hardtanh()\n",
    "    self.act = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.layer3(self.act(self.layer2(self.act(self.layer1(x)))))\n",
    "\n",
    "  def output(self, x):\n",
    "    out1 = self.act(self.layer1(x))\n",
    "    out2 = self.act(self.layer2(out1))\n",
    "    out3 = self.layer3(out2)\n",
    "    return out1, out2, out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Suh22BC9tMTj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_model(\n",
      "  (layer1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (layer3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (act): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = mnist_model().cuda()\n",
    "print(model)\n",
    "\n",
    "epochs = 15\n",
    "lr = 0.1\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lrs = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ztvyum2f-XqU"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pOYNVw8B-aKz"
   },
   "outputs": [],
   "source": [
    "def get_acc(model, loader):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for img, label in loader:\n",
    "    correct += torch.sum(torch.argmax(model(img.cuda().view(-1, 784)), -1).cpu() == label).item()\n",
    "    total += len(img)\n",
    "  return 100*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yk0nHkbhtPkz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.1\n",
      "Epoch 0, training accuracy 90.51166666666667, test accuracy 90.76\n",
      "lr 0.09890738003669029\n",
      "Epoch 1, training accuracy 93.8, test accuracy 93.77\n",
      "lr 0.09567727288213004\n",
      "Epoch 2, training accuracy 95.15166666666667, test accuracy 95.22\n",
      "lr 0.09045084971874738\n",
      "Epoch 3, training accuracy 96.1, test accuracy 95.84\n",
      "lr 0.08345653031794292\n",
      "Epoch 4, training accuracy 96.74166666666666, test accuracy 96.29\n",
      "lr 0.07500000000000001\n",
      "Epoch 5, training accuracy 96.95666666666666, test accuracy 96.34\n",
      "lr 0.06545084971874739\n",
      "Epoch 6, training accuracy 97.125, test accuracy 96.59\n",
      "lr 0.05522642316338269\n",
      "Epoch 7, training accuracy 97.76666666666667, test accuracy 96.92\n",
      "lr 0.04477357683661735\n",
      "Epoch 8, training accuracy 97.88666666666667, test accuracy 97.05\n",
      "lr 0.03454915028125265\n",
      "Epoch 9, training accuracy 97.95166666666667, test accuracy 97.22\n",
      "lr 0.02500000000000002\n",
      "Epoch 10, training accuracy 98.12166666666667, test accuracy 97.2\n",
      "lr 0.01654346968205711\n",
      "Epoch 11, training accuracy 98.20166666666667, test accuracy 97.42\n",
      "lr 0.009549150281252635\n",
      "Epoch 12, training accuracy 98.26, test accuracy 97.42\n",
      "lr 0.004322727117869953\n",
      "Epoch 13, training accuracy 98.26333333333334, test accuracy 97.49\n",
      "lr 0.001092619963309716\n",
      "Epoch 14, training accuracy 98.27833333333334, test accuracy 97.48\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    counter = 0\n",
    "  print(\"lr\", optimizer.param_groups[0][\"lr\"])\n",
    "  for img, label in train_loader:\n",
    "    if counter ==4:\n",
    "        break\n",
    "    out = model(img.cuda().view(-1, 784))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(out, label.cuda())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    counter++\n",
    "  lrs.step()\n",
    "  print(f\"Epoch {e}, training accuracy {get_acc(model, train_loader)}, test accuracy {get_acc(model, test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QsQBF-eWFDY7"
   },
   "source": [
    "## Extract weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CdQe9RA0vthi"
   },
   "outputs": [],
   "source": [
    "params = [(name, p.data.cpu().numpy()) for (name, p) in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DO_6VdePwxF_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer layer1, type weight, shape (128, 784)\n",
      "Layer layer1, type bias, shape (128,)\n",
      "Layer layer2, type weight, shape (128, 128)\n",
      "Layer layer2, type bias, shape (128,)\n",
      "Layer layer3, type weight, shape (10, 128)\n",
      "Layer layer3, type bias, shape (10,)\n"
     ]
    }
   ],
   "source": [
    "for (name, p) in params:\n",
    "  print(f\"Layer {name.split('.')[0]}, type {name.split('.')[1]}, shape {p.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lypaj9GkFrUU"
   },
   "outputs": [],
   "source": [
    "# print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVz78PBcFzka"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(512, 784) (512, 10)\n",
      "0\n",
      "128\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for img, label in train_loader:\n",
    "    img = img.cuda().view(-1, 784).tolist()\n",
    "    label  = label.tolist()\n",
    "    if counter == 5:\n",
    "        break\n",
    "    if counter == 0:\n",
    "        counter+=1\n",
    "        continue\n",
    "    \n",
    "    print(len(label))\n",
    "    b = np.zeros((len(label), 10))\n",
    "    b[np.arange(len(label)),label] = 1\n",
    "    if counter>1:\n",
    "        img_multiple=np.concatenate((img_multiple,np.array(img)))\n",
    "        label_multiple=np.concatenate((label_multiple,np.array(b)))\n",
    "    else:\n",
    "        img_multiple = np.array(img)\n",
    "        label_multiple = np.array(b)\n",
    "    counter+=1\n",
    "print(label_multiple)\n",
    "print(img_multiple.shape,label_multiple.shape)\n",
    "zero_img = np.zeros(img_multiple.shape)\n",
    "zero_label = np.zeros(label_multiple.shape)\n",
    "np.savetxt(fname=\"./MNIST/train_data_0\", delimiter=\" \", X=img_multiple.tolist())\n",
    "np.savetxt(fname=\"./MNIST/train_data_1\", delimiter=\" \", X=zero_img.tolist())\n",
    "np.savetxt(fname=\"./MNIST/train_data_2\", delimiter=\" \", X=zero_img.tolist())\n",
    "np.savetxt(fname=\"./MNIST/train_labels_0\", delimiter=\" \", X=label_multiple.tolist())\n",
    "np.savetxt(fname=\"./MNIST/train_labels_1\", delimiter=\" \", X=zero_label.tolist())\n",
    "np.savetxt(fname=\"./MNIST/train_labels_2\", delimiter=\" \", X=zero_label.tolist())\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for img, label in test_loader:\n",
    "    print(counter)\n",
    "    img = img.cuda().view(-1, 784).tolist()\n",
    "    label  = label.tolist()\n",
    "    if counter:\n",
    "        break\n",
    "    \n",
    "    print(len(label))\n",
    "    b = np.zeros((len(label), 10))\n",
    "    b[np.arange(len(label)),label] = 1\n",
    "\n",
    "    img_multiple = np.array(img)\n",
    "    label_multiple = np.array(b)\n",
    "    counter+=1\n",
    "zero_img = np.zeros(img_multiple.shape)\n",
    "zero_label = np.zeros(label_multiple.shape)\n",
    "np.savetxt(fname=\"./MNIST/test_data_0\", delimiter=\" \", X=img_multiple.tolist())\n",
    "np.savetxt(fname=\"./MNIST/test_data_1\", delimiter=\" \", X=zero_img.tolist())\n",
    "np.savetxt(fname=\"./MNIST/test_data_2\", delimiter=\" \", X=zero_img.tolist())\n",
    "np.savetxt(fname=\"./MNIST/test_labels_0\", delimiter=\" \", X=label_multiple.tolist())\n",
    "np.savetxt(fname=\"./MNIST/test_labels_1\", delimiter=\" \", X=zero_label.tolist())\n",
    "np.savetxt(fname=\"./MNIST/test_labels_2\", delimiter=\" \", X=zero_label.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACfBKOB3v7Dm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.875\n"
     ]
    }
   ],
   "source": [
    "for img, label in test_loader:\n",
    "    break\n",
    "path = \"./SecureML/\"\n",
    "import os\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "np.savetxt(fname=path+\"label\", delimiter=\" \", X=label.tolist())\n",
    "print(get_acc(model, ([img,label],)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eiqkXaaBZUci"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "np.savetxt(fname=path+\"input_0\", delimiter=\" \", X=img.cuda().view(-1, 784).tolist())\n",
    "np.savetxt(fname=path+\"outputlayer1_0\", delimiter=\" \", X=model.output(img.cuda().view(-1, 784))[0].tolist())\n",
    "np.savetxt(fname=path+\"outputlayer2_0\", delimiter=\" \", X=model.output(img.cuda().view(-1, 784))[1].tolist())\n",
    "np.savetxt(fname=path+\"outputlayer3_0\", delimiter=\" \", X=model.output(img.cuda().view(-1, 784))[2].tolist())\n",
    "\n",
    "np.savetxt(fname=path+\"weight1_0\", delimiter=\" \", X=params[0][1].tolist())\n",
    "np.savetxt(fname=path+\"bias1_0\", delimiter=\" \",  X=params[1][1].tolist())\n",
    "np.savetxt(fname=path+\"weight2_0\", delimiter=\" \", X=params[2][1].tolist())\n",
    "np.savetxt(fname=path+\"bias2_0\", delimiter=\" \", X=params[3][1].tolist())\n",
    "np.savetxt(fname=path+\"weight3_0\", delimiter=\" \", X=params[4][1].tolist())\n",
    "np.savetxt(fname=path+\"bias3_0\", delimiter=\" \", X=params[5][1].tolist())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_SecureML.ipynb",
   "provenance": [
    {
     "file_id": "1G0aq7Vn-bomx5TTWCkUXm2iAPtQjYxxl",
     "timestamp": 1597179603592
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
