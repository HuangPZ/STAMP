{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyFvxvSgsTqQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-uJEFsv4tBBY"
   },
   "source": [
    "## Lets get the data, model and setup trainnig code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KaC8fIULs7XK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24c70b1ba66451380a366de3694dd1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bb243ff0714aac9ce8e402377e5a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856624d8f9bf43388fc7d66bde86a168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c170c28ec7467cacc0c0d25a8a126d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Training images 60000, Test images 10000\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(datasets.MNIST(\"./\", train=True, transform=transforms.ToTensor(), download=True), batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(datasets.MNIST(\"./\", train=False, transform=transforms.ToTensor(), download=True), batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Training images {len(train_loader.dataset)}, Test images {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRKHX6Ssp2Hz"
   },
   "outputs": [],
   "source": [
    "class mnist_model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(mnist_model, self).__init__()\n",
    "    self.layer1 = nn.Conv2d(1, 20, kernel_size=5, stride=1, padding=0)\n",
    "    self.layer2 = nn.Conv2d(20, 50, kernel_size=5, stride=1, padding=0)\n",
    "    self.layer3 = nn.Linear(800, 500, bias=True)\n",
    "    self.layer4 = nn.Linear(500, 10, bias=True)\n",
    "\n",
    "    self.act = nn.ReLU()\n",
    "    self.pool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.act(self.layer1(x))\n",
    "    out = self.pool(out)\n",
    "    out = self.act(self.layer2(out))\n",
    "    out = self.pool(out)\n",
    "    out = out.view(-1, 800)\n",
    "    out = self.act(self.layer3(out))\n",
    "    out = self.act(self.layer4(out))\n",
    "    return out\n",
    "\n",
    "  def output(self, x):\n",
    "    out1 = self.act(self.layer1(x))\n",
    "    out1 = self.pool(out1)\n",
    "    out2 = self.act(self.layer2(out1))\n",
    "    out2 = self.pool(out2)\n",
    "    out2 = out2.view(-1, 800)\n",
    "    out3 = self.act(self.layer3(out2))\n",
    "    out4 = self.act(self.layer4(out3))    \n",
    "    return out1, out2, out3, out4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Suh22BC9tMTj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_model(\n",
      "  (layer1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (layer2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (layer3): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (layer4): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (act): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = mnist_model().cuda()\n",
    "print(model)\n",
    "\n",
    "epochs = 15\n",
    "lr = 0.1\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lrs = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ztvyum2f-XqU"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pOYNVw8B-aKz"
   },
   "outputs": [],
   "source": [
    "def get_acc(model, loader):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for img, label in loader:\n",
    "    correct += torch.sum(torch.argmax(model(img.cuda()), -1).cpu() == label).item()\n",
    "    total += len(img)\n",
    "  return 100*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yk0nHkbhtPkz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.1\n",
      "Epoch 0, training accuracy 95.05166666666666, test accuracy 95.54\n",
      "lr 0.09890738003669029\n",
      "Epoch 1, training accuracy 97.94666666666667, test accuracy 97.87\n",
      "lr 0.09567727288213004\n",
      "Epoch 2, training accuracy 98.69333333333333, test accuracy 98.78\n",
      "lr 0.09045084971874738\n",
      "Epoch 3, training accuracy 98.89666666666666, test accuracy 98.7\n",
      "lr 0.08345653031794292\n",
      "Epoch 4, training accuracy 98.91, test accuracy 98.8\n",
      "lr 0.07500000000000001\n",
      "Epoch 5, training accuracy 99.205, test accuracy 98.86\n",
      "lr 0.06545084971874739\n",
      "Epoch 6, training accuracy 99.47, test accuracy 99.01\n",
      "lr 0.05522642316338269\n",
      "Epoch 7, training accuracy 99.49333333333334, test accuracy 99.04\n",
      "lr 0.04477357683661735\n",
      "Epoch 8, training accuracy 99.59, test accuracy 99.07\n",
      "lr 0.03454915028125265\n",
      "Epoch 9, training accuracy 99.66, test accuracy 99.12\n",
      "lr 0.02500000000000002\n",
      "Epoch 10, training accuracy 99.70166666666667, test accuracy 99.15\n",
      "lr 0.01654346968205711\n",
      "Epoch 11, training accuracy 99.76333333333334, test accuracy 99.12\n",
      "lr 0.009549150281252635\n",
      "Epoch 12, training accuracy 99.77833333333334, test accuracy 99.13\n",
      "lr 0.004322727117869953\n",
      "Epoch 13, training accuracy 99.78833333333333, test accuracy 99.13\n",
      "lr 0.001092619963309716\n",
      "Epoch 14, training accuracy 99.78833333333333, test accuracy 99.14\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "  print(\"lr\", optimizer.param_groups[0][\"lr\"])\n",
    "  for img, label in train_loader:\n",
    "    # print(img.shape, label.shape)\n",
    "    out = model(img.cuda())\n",
    "    # print(out.shape)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(out, label.cuda())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  lrs.step()\n",
    "  print(f\"Epoch {e}, training accuracy {get_acc(model, train_loader)}, test accuracy {get_acc(model, test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QsQBF-eWFDY7"
   },
   "source": [
    "## Extract weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CdQe9RA0vthi"
   },
   "outputs": [],
   "source": [
    "params = [(name, p.data.cpu().numpy()) for (name, p) in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DO_6VdePwxF_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer layer1, type weight, shape (20, 1, 5, 5)\n",
      "Layer layer1, type bias, shape (20,)\n",
      "Layer layer2, type weight, shape (50, 20, 5, 5)\n",
      "Layer layer2, type bias, shape (50,)\n",
      "Layer layer3, type weight, shape (500, 800)\n",
      "Layer layer3, type bias, shape (500,)\n",
      "Layer layer4, type weight, shape (10, 500)\n",
      "Layer layer4, type bias, shape (10,)\n"
     ]
    }
   ],
   "source": [
    "for (name, p) in params:\n",
    "  print(f\"Layer {name.split('.')[0]}, type {name.split('.')[1]}, shape {p.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lypaj9GkFrUU"
   },
   "outputs": [],
   "source": [
    "#print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcatFuNhe1fY"
   },
   "source": [
    "## Visualize hidden activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r6lxIEFReMxL"
   },
   "outputs": [],
   "source": [
    "# print(model.children())\n",
    "# out = list(model.children())[0](img.cuda()).data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4rd-AKLbeL-A"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# for _ in range(out.shape[1]):\n",
    "#   plt.figure(figsize=(1, 1))\n",
    "#   plt.imshow(out[0, 0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVz78PBcFzka"
   },
   "outputs": [],
   "source": [
    "for img, label in train_loader:\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 0, 1, 4, 6, 3, 3, 1, 4, 7, 0, 4, 2, 8, 4, 5, 9, 0, 3, 1, 0, 5, 2, 2,\n",
      "        2, 9, 8, 5, 8, 7, 3, 0, 5, 7, 0, 0, 1, 7, 1, 9, 1, 3, 0, 6, 0, 9, 6, 1,\n",
      "        6, 4, 1, 3, 7, 2, 2, 7, 4, 4, 1, 1, 5, 4, 4, 4, 1, 1, 9, 7, 3, 4, 2, 4,\n",
      "        4, 1, 2, 9, 7, 5, 6, 8, 3, 8, 9, 1, 1, 1, 1, 2, 6, 9, 7, 4, 7, 5, 3, 5,\n",
      "        6, 4, 7, 0, 8, 6, 6, 3, 8, 4, 4, 9, 2, 8, 9, 0, 3, 6, 0, 4, 6, 3, 3, 7,\n",
      "        2, 5, 1, 7, 9, 8, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACfBKOB3v7Dm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"./LeNet/\"\n",
    "import os\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "np.savetxt(fname=path+\"label\", delimiter=\" \", X=label.tolist())\n",
    "print(get_acc(model, ([img,label],)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eiqkXaaBZUci"
   },
   "outputs": [],
   "source": [
    "\n",
    "np.savetxt(fname=path+\"input_0\", delimiter=\" \", X=img.cuda().view(-1, 784).tolist())\n",
    "np.savetxt(fname=path+\"outputlayer1_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[0].data.cpu().view(-1))\n",
    "np.savetxt(fname=path+\"outputlayer2_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[1].tolist())\n",
    "np.savetxt(fname=path+\"outputlayer3_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[2].tolist())\n",
    "np.savetxt(fname=path+\"outputlayer4_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[3].tolist())\n",
    "\n",
    "np.savetxt(fname=path+\"weight1_0\", delimiter=\" \", X=params[0][1].reshape(5*5*1, 20).tolist())\n",
    "np.savetxt(fname=path+\"bias1_0\", delimiter=\" \", X=params[1][1].tolist())\n",
    "np.savetxt(fname=path+\"weight2_0\", delimiter=\" \", X=params[2][1].reshape(5*5*20, 50).tolist())\n",
    "np.savetxt(fname=path+\"bias2_0\", delimiter=\" \", X=params[3][1].tolist())\n",
    "np.savetxt(fname=path+\"weight3_0\", delimiter=\" \", X=params[4][1].tolist())\n",
    "np.savetxt(fname=path+\"bias3_0\", delimiter=\" \", X=params[5][1].tolist())\n",
    "np.savetxt(fname=path+\"weight4_0\", delimiter=\" \", X=params[6][1].tolist())\n",
    "np.savetxt(fname=path+\"bias4_0\", delimiter=\" \", X=params[7][1].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_LeNet.ipynb",
   "provenance": [
    {
     "file_id": "1G0aq7Vn-bomx5TTWCkUXm2iAPtQjYxxl",
     "timestamp": 1597179603592
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
